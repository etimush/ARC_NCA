{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Datasets for graphs",
   "id": "da083bd05a11cbea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "name = \"LossesData/v4_loss.json\"\n",
    "with open(name, \"r\") as f:\n",
    "    all_problems_loss_history = json.load(f)\n",
    "\n",
    "name = \"LossesData/v4_eval.json\"\n",
    "with open(name, \"r\") as f:\n",
    "    all_problems_eval_history = json.load(f)\n",
    "\n"
   ],
   "id": "1f312bf7aba97aa2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Make graphs and relevant data",
   "id": "acf3904aca3182c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_1 = [min(v) if v[-1] <0 else 0 for k,v in all_problems_loss_history.items()]\n",
    "data_2 = [min(v) if v[-1] <0 else 0 for k,v in all_problems_eval_history.items()]\n",
    "\n",
    "\n",
    "minimum_2 = [(idx,v) for idx,v in enumerate(data_2)]\n",
    "\n",
    "minimum_2.sort(key=lambda x:x[1], reverse=True)\n",
    "solve_rate = 100*sum([1 for i in range(len(data_2)) if data_2[i] <= -7])/len(data_2)\n",
    "print(minimum_2[1])\n",
    "print(solve_rate)"
   ],
   "id": "6154f35f5316e7ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.title(\"Final Training Loss Versus Final Eval Loss\")\n",
    "plt.scatter(data_2,data_1)\n",
    "plt.show()\n",
    "corre_coef = np.corrcoef(data_1, data_2)\n",
    "print(corre_coef)"
   ],
   "id": "7fb79c4d5cf6c4c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.title(\"Final Training Losses\")\n",
    "plt.bar([i for i in range(len(data_1))],data_1)"
   ],
   "id": "d61cb0da202e46a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.title(\"Final Eval Losses\")\n",
    "plt.bar([i for i in range(len(data_2))],data_2)"
   ],
   "id": "c45b7d9852da8750",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.title(\"Distribution of training losses\")\n",
    "plt.hist(data_1, bins=20)"
   ],
   "id": "a8f49b12d7d10d2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.title(\"Distribution of Eval losses\")\n",
    "plt.hist(data_2, bins=20)"
   ],
   "id": "aa31813f279e20b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_3 = [min(v) for k,v in all_problems_loss_history.items()]\n",
    "data_4 = [min(v) for k,v in all_problems_eval_history.items()]\n",
    "print(data_3[7])"
   ],
   "id": "6310ba6c295d26a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.title(\"Min Training Loss Versus Min Eval Loss\")\n",
    "plt.scatter(data_3,data_4)\n",
    "plt.show()\n",
    "corre_coef = np.corrcoef(data_3, data_4)\n",
    "print(corre_coef)"
   ],
   "id": "51b38268c1fd06e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.title(\"Min Training Losses\")\n",
    "plt.bar([i for i in range(len(data_3))],data_3)"
   ],
   "id": "edf3a33ee20344e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.title(\"Min Eval Losses\")\n",
    "plt.bar([i for i in range(len(data_4))],data_4)"
   ],
   "id": "c0329cffa27f0d4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.title(\"Distribution of min training losses\")\n",
    "plt.hist(data_3, bins=20)"
   ],
   "id": "afebbdb508b4732d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.title(\"Distribution of min eval losses\")\n",
    "plt.hist(data_4, bins=20)"
   ],
   "id": "17ef2c009526ff53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load all datasets in folder",
   "id": "ad7ff2bf8e61a81f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dirr = \"LossesData\"\n",
    "sets = [os.path.join(dirr, file) for file in os.listdir(dirr)]\n",
    "data_dict = {}\n",
    "for s in sets:\n",
    "\n",
    "    with open(s, \"r\") as f:\n",
    "        history = json.load(f)\n",
    "        data_dict[s] = history\n",
    "\n"
   ],
   "id": "a3f82f32b2398608",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Functions for comparing data sets",
   "id": "2ef5c63a92501426"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compare_data_sets(set1, set2):\n",
    "    data_1 = [v[-1] if v[-1] < 0 else 0 for k,v in set1.items()]\n",
    "    data_2 = [v[-1] if v[-1] < 0 else 0 for k,v in set2.items()]\n",
    "    set_1 = set([i for i,v in enumerate(data_1) if v < -6])\n",
    "    set_2 = set([i for i,v in enumerate(data_2) if v < -6])\n",
    "    union = set_1.union(set_2)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.bar([i for i in range(len(data_1))],data_1, color=\"b\")\n",
    "    plt.bar([i for i in range(len(data_2))],data_2, color=\"r\", alpha=0.7)\n",
    "    comp = [1 for i in range(len(data_1)) if data_1[i] < data_2[i]]\n",
    "    plt.figure(2)\n",
    "    range_low = min(min(data_1), min(data_2))\n",
    "    range_high = max(max(data_1), max(data_2))\n",
    "    plt.hist(data_1, bins=40, color=\"b\", range=(range_low, range_high))\n",
    "    plt.hist(data_2, bins=40, color=\"r\", alpha=0.7, range=(range_low, range_high))\n",
    "    perc_1 = [1 for i in range(len(data_1)) if data_1[i] < -6]\n",
    "    perc_2 = [1 for i in range(len(data_2)) if data_2[i] < -6]\n",
    "    print(\"First Average: \", sum(data_1) / len(data_1))\n",
    "    print(\"Second Average: \", sum(data_2) / len(data_2))\n",
    "    print(f\"Firsat Data performs better in {sum(comp)} of {len(data_1)} of cases, \\\"{sum(comp) / len(data_1) * 100}%\\\" \")\n",
    "    print(f\"The solve rate for the first data set is {100*(sum(perc_1) / len(data_1))}%\")\n",
    "    print(f\"The solve rate for the second data set is {100*(sum(perc_2) / len(data_2))}%\")\n",
    "    print(f\"Combined solve rate is {len(union) / len(data_1) * 100}%\")\n",
    "\n",
    "    plt.show()\n",
    "def get_total_solve(data_points):\n",
    "    all_data = [[v[-1] if v[-1] < 0 else 0 for k,v in set1.items()] for set1 in data_points]\n",
    "    all_sets = [set([i for i,v in enumerate(data_1) if (v < -6) ]) for data_1 in all_data]\n",
    "    set_tot = all_sets[0]\n",
    "    set_mean = sum(all_data[0])/len(all_data[0])\n",
    "    print(all_sets[0])\n",
    "    for i in range(1, len(all_sets)):\n",
    "        set_tot = set_tot.union(all_sets[i])\n",
    "        mean = sum(all_data[i])/len(all_data[i])\n",
    "        print(all_sets[i])\n",
    "        set_mean += mean\n",
    "\n",
    "    set_mean = set_mean/len(all_data)\n",
    "    print(f\"Mean of all data sets is {set_mean}\")\n",
    "    print(f\"The total solve for all data sets is {len(set_tot)/len(all_data[0])*100}%\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "9fe5c99e8799dba8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Get solve rate and problems solved",
   "id": "71e27fe895050277"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "get_total_solve([data_dict[\"LossesData/v3_padded_eval.json\"], data_dict[\"LossesData/v3_padded_eval.json\"]])",
   "id": "11dc1d8257307315",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compare data sets",
   "id": "e41400fead3d566a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "compare_data_sets(data_dict[\"LossesData/v3_padded_eval.json\"], data_dict[\"LossesData/v3_padded_eval.json\"])",
   "id": "2ff81313786a266e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "compare_data_sets(data_dict[\"LossesData/ca_eval.json\"], data_dict[\"LossesData/v1_eval.json\"])",
   "id": "5f9b47e1721cadca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "compare_data_sets(data_dict[\"LossesData/ca_eval.json\"], data_dict[\"LossesData/v2_eval.json\"])",
   "id": "89b866495512bebd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "compare_data_sets(data_dict[\"LossesData/ca_eval.json\"], data_dict[\"LossesData/v3_eval.json\"])",
   "id": "43ba23ab05ca078",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9df6dac0b761b05f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
